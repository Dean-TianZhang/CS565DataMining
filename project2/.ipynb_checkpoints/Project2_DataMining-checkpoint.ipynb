{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 300 words:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I try to count the most frequent 300 in our dataset, and then choose 20 adjective words to build dummy vector to present each review content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "top_N = 300\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "# RegEx for stopwords\n",
    "RE_stopwords = r'\\b(?:{})\\b'.format('|'.join(stopwords))\n",
    "# replace '|'-->' ' and drop all stopwords\n",
    "words = (df_train['content']\n",
    "           .str.lower()\n",
    "           .replace([r'\\|', RE_stopwords], [' ', ''], regex=True)\n",
    "           .str.cat(sep=' ')\n",
    "           .split()\n",
    ")\n",
    "\n",
    "# generate DF out of Counter\n",
    "rslt = pd.DataFrame(Counter(words).most_common(top_N),\n",
    "                    columns=['Word', 'Frequency']).set_index('Word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>worth</th>\n",
       "      <td> 1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td> 1178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whole</th>\n",
       "      <td> 1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landed</th>\n",
       "      <td> 1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missed</th>\n",
       "      <td> 1161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Frequency\n",
       "Word             \n",
       "worth        1179\n",
       "15           1178\n",
       "whole        1175\n",
       "landed       1165\n",
       "missed       1161"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['good'] = df_train['content'].str.contains(\"good\")\n",
    "df_train['new']= df_train['content'].str.contains(\"new\")\n",
    "df_train['economy']= df_train['content'].str.contains(\"economy\")\n",
    "df_train['friendly']= df_train['content'].str.contains(\"friendly\")\n",
    "df_train['delayed']= df_train['content'].str.contains(\"delayed\")\n",
    "df_train['comfortable']= df_train['content'].str.contains(\"comfortable\")\n",
    "df_train['great']= df_train['content'].str.contains(\"great\")\n",
    "df_train['excellent']= df_train['content'].str.contains(\"excellent\")\n",
    "df_train['old']= df_train['content'].str.contains(\"old\")\n",
    "df_train['better']= df_train['content'].str.contains(\"better\")\n",
    "df_train['late']= df_train['content'].str.contains(\"late\")\n",
    "df_train['well']= df_train['content'].str.contains(\"well\")\n",
    "df_train['quite']= df_train['content'].str.contains(\"quite\")\n",
    "df_train['small']= df_train['content'].str.contains(\"small\")\n",
    "df_train['clean']= df_train['content'].str.contains(\"clean\")\n",
    "df_train['poor']= df_train['content'].str.contains(\"poor\")\n",
    "df_train['delay']= df_train['content'].str.contains(\"delay\")\n",
    "df_train['bad']= df_train['content'].str.contains(\"bad\")\n",
    "df_train['best']= df_train['content'].str.contains(\"best\")\n",
    "df_train['helpful']= df_train['content'].str.contains(\"helpful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['good'] = df_test['content'].str.contains(\"good\")\n",
    "df_test['new']= df_test['content'].str.contains(\"new\")\n",
    "df_test['economy']= df_test['content'].str.contains(\"economy\")\n",
    "df_test['friendly']= df_test['content'].str.contains(\"friendly\")\n",
    "df_test['delayed']= df_test['content'].str.contains(\"delayed\")\n",
    "df_test['comfortable']= df_test['content'].str.contains(\"comfortable\")\n",
    "df_test['great']= df_test['content'].str.contains(\"great\")\n",
    "df_test['excellent']= df_test['content'].str.contains(\"excellent\")\n",
    "df_test['old']= df_test['content'].str.contains(\"old\")\n",
    "df_test['better']= df_test['content'].str.contains(\"better\")\n",
    "df_test['late']= df_test['content'].str.contains(\"late\")\n",
    "df_test['well']= df_test['content'].str.contains(\"well\")\n",
    "df_test['quite']= df_test['content'].str.contains(\"quite\")\n",
    "df_test['small']= df_test['content'].str.contains(\"small\")\n",
    "df_test['clean']= df_test['content'].str.contains(\"clean\")\n",
    "df_test['poor']= df_test['content'].str.contains(\"poor\")\n",
    "df_test['delay']= df_test['content'].str.contains(\"delay\")\n",
    "df_test['bad']= df_test['content'].str.contains(\"bad\")\n",
    "df_test['best']= df_test['content'].str.contains(\"best\")\n",
    "df_test['helpful']= df_test['content'].str.contains(\"helpful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_columns = ['good',\n",
    "                    'new',\n",
    "                    'economy',\n",
    "                    'friendly',\n",
    "                    'delayed',\n",
    "                    'comfortable',\n",
    "                    'great',\n",
    "                    'excellent',\n",
    "                    'old',\n",
    "                    'better',\n",
    "                    'late',\n",
    "                    'well',\n",
    "                    'quite',\n",
    "                    'small',\n",
    "                    'clean',\n",
    "                    'poor',\n",
    "                    'delay',\n",
    "                    'bad',\n",
    "                    'best',\n",
    "                    'helpful',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train[review_columns] = df_train[review_columns].astype(int)\n",
    "df_test[review_columns] = df_test[review_columns].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the missing value in column 'cabin_flown' and 'type_traveller' to Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['cabin_flown'] = df_train.cabin_flown.fillna(value='Unknown')\n",
    "df_train['type_traveller'] = df_train.type_traveller.fillna(value='Unknown')\n",
    "df_test['cabin_flown'] = df_test.cabin_flown.fillna(value='Unknown')\n",
    "df_test['type_traveller'] = df_test.type_traveller.fillna(value='Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those eight rating attributes, I try to use the mean of each column to represent the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['overall_rating', \n",
    "                 'seat_comfort_rating', \n",
    "                 'cabin_staff_rating', \n",
    "                 'food_beverages_rating', \n",
    "                 'inflight_entertainment_rating', \n",
    "                 'ground_service_rating', \n",
    "                 'wifi_connectivity_rating', \n",
    "                 'value_money_rating']\n",
    "imputer = Imputer(missing_values = 'NaN',strategy='mean',axis=0)\n",
    "imputer = imputer.fit(df_train[columns])\n",
    "imputer_data = imputer.transform(df_train[columns])\n",
    "df_train[columns] = imputer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputer = imputer.fit(df_test[columns])\n",
    "df_test[columns] = imputer.transform(df_test[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I try to convert date to four seasons dummy variable. It takes time to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "d = datetime.date.today()\n",
    "df_train['date']=pd.to_datetime(df_train['date'])\n",
    "df_train['month']=df_train['date'].dt.month\n",
    "df_test['date']=pd.to_datetime(df_test['date'])\n",
    "df_test['month']=df_test['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['winter']=0\n",
    "df_train['spring']=0\n",
    "df_train['summer']=0\n",
    "df_train['autumn']=0\n",
    "df_test['winter']=0\n",
    "df_test['spring']=0\n",
    "df_test['summer']=0\n",
    "df_test['autumn']=0\n",
    "winterMonths = [12,1,2]\n",
    "springMonths = [3,4,5]\n",
    "summerMonths = [6,7,8]\n",
    "autumnMonths = [9,10,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in df_train.iterrows():\n",
    "    if df_train.loc[index, 'month'] in winterMonths:\n",
    "        df_train.loc[index, 'winter'] = 1\n",
    "    if df_train.loc[index, 'month'] in springMonths:\n",
    "        df_train.loc[index, 'spring'] = 1\n",
    "    if df_train.loc[index, 'month'] in summerMonths:\n",
    "        df_train.loc[index, 'summer'] = 1\n",
    "    if df_train.loc[index, 'month'] in autumnMonths:\n",
    "        df_train.loc[index, 'autumn'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in df_test.iterrows():\n",
    "    if df_test.loc[index, 'month'] in winterMonths:\n",
    "        df_test.loc[index, 'winter'] = 1\n",
    "    if df_test.loc[index, 'month'] in springMonths:\n",
    "        df_test.loc[index, 'spring'] = 1\n",
    "    if df_test.loc[index, 'month'] in summerMonths:\n",
    "        df_test.loc[index, 'summer'] = 1\n",
    "    if df_test.loc[index, 'month'] in autumnMonths:\n",
    "        df_test.loc[index, 'autumn'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_list = ['cabin_flown', 'type_traveller']\n",
    "df_train = pd.get_dummies(df_train, columns=encoded_list)\n",
    "df_test = pd.get_dummies(df_test, columns=encoded_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'airline_name', 'link', 'title', 'author', 'author_country', 'date', 'content', 'aircraft', 'route', 'overall_rating', 'seat_comfort_rating', 'cabin_staff_rating', 'food_beverages_rating', 'inflight_entertainment_rating', 'ground_service_rating', 'wifi_connectivity_rating', 'value_money_rating', 'recommended', 'good', 'new', 'economy', 'friendly', 'delayed', 'comfortable', 'great', 'excellent', 'old', 'better', 'late', 'well', 'quite', 'small', 'clean', 'poor', 'delay', 'bad', 'best', 'helpful', 'worst', 'available', 'recommend', 'efficient', 'pleasant', 'uncomfortable', 'cancelled', 'rude', 'pretty', 'fine', 'month', 'winter', 'spring', 'summer', 'autumn', 'cabin_flown_Business Class', 'cabin_flown_Economy', 'cabin_flown_First Class', 'cabin_flown_Premium Economy', 'cabin_flown_Unknown', 'type_traveller_Business', 'type_traveller_Couple Leisure', 'type_traveller_FamilyLeisure', 'type_traveller_Solo Leisure', 'type_traveller_Unknown'], dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosen_columns = ['cabin_flown_Business Class', \n",
    "                  'cabin_flown_Economy', \n",
    "                  'cabin_flown_First Class', \n",
    "                  'cabin_flown_Premium Economy', \n",
    "                  'cabin_flown_Unknown', \n",
    "                  'type_traveller_Business', \n",
    "                  'type_traveller_Couple Leisure', \n",
    "                  'type_traveller_FamilyLeisure', \n",
    "                  'type_traveller_Solo Leisure', \n",
    "                  'type_traveller_Unknown',\n",
    "                  'overall_rating', \n",
    "                  'seat_comfort_rating', \n",
    "                  'cabin_staff_rating', \n",
    "                  'food_beverages_rating', \n",
    "                  'inflight_entertainment_rating', \n",
    "                  'ground_service_rating', \n",
    "                  'wifi_connectivity_rating', \n",
    "                  'value_money_rating',\n",
    "                 'good', 'new', 'economy', 'friendly', \n",
    "                  'delayed', 'comfortable', 'great', \n",
    "                  'excellent', 'old', 'better', 'late', \n",
    "                  'well', 'quite', 'small', 'clean', \n",
    "                  'poor', 'delay', 'bad', 'best', 'helpful',\n",
    "                  'winter', 'spring', 'summer', 'autumn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = df_train[chosen_columns]\n",
    "x_test = df_test[chosen_columns]\n",
    "y_train = df_train['recommended']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_train_scaled = preprocessing.scale(x_train)\n",
    "X_test_scaled = preprocessing.scale(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning for Random Forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://www.kaggle.com/hadend/tuning-random-forest-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import cross_validation\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "\n",
    "def evaluate_param(parameter, num_range, index):\n",
    "    grid_search = GridSearchCV(clf, param_grid = {parameter: num_range})\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    df = {}\n",
    "    for i, score in enumerate(grid_search.grid_scores_):\n",
    "        df[score[0][parameter]] = score[1]\n",
    "       \n",
    "    \n",
    "    df = pd.DataFrame.from_dict(df, orient='index')\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    df = df.sort(axis='index')\n",
    " \n",
    "    plt.subplot(3,2,index)\n",
    "    plot = plt.plot(df['index'], df[0])\n",
    "    plt.title(parameter)\n",
    "    return plot, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\": np.arange(2, 1000, 2),\n",
    "              \"max_depth\": np.arange(2, 28, 1),\n",
    "              \"min_samples_split\": np.arange(2,150,1),\n",
    "              \"min_samples_leaf\": np.arange(2,60,1),\n",
    "              \"max_leaf_nodes\": np.arange(2,60,1),\n",
    "              \"min_weight_fraction_leaf\": np.arange(0.1,0.4, 0.1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = 1\n",
    "plt.figure(figsize=(16,12))\n",
    "for parameter, param_range in dict.items(param_grid):   \n",
    "    evaluate_param(parameter, param_range, index)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=1000, n_jobs=2, oob_score=False, random_state=100,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_jobs=2,n_estimators=1000,random_state=100,max_features='auto')\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = model.predict(X_test_scaled)\n",
    "result = pd.DataFrame(columns=['id', 'recommended'])\n",
    "result['id'] = df_test.id\n",
    "result['recommended'] = y_test\n",
    "result.to_csv('result15.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
